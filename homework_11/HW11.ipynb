{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    START = '*'\n",
    "    TERM = '$'\n",
    "    REST = '$REST$' # to deal with observed states who have never appeared in train dataset.\n",
    "        \n",
    "    def cond_idx(self, u, v):\n",
    "        return u + v*self.h_dim\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X - list of lists, observed states\n",
    "        y - list of lists, hidden states\n",
    "        estimate elements of A, B matrices from train sequence. \n",
    "        \"\"\"\n",
    "        \n",
    "        #######################\n",
    "        # YOUR CODE HERE\n",
    "        y_unique = []\n",
    "        for hid_list in y:\n",
    "            for hid_state in hid_list:\n",
    "                if hid_state not in y_unique:\n",
    "                    y_unique.append(hid_state)\n",
    "        y_unique.append(START)\n",
    "        y_unique.append(TERM)\n",
    "        self.hidden_idx2state = y_unique # lisf of unique hidden states in train sequence + [START, TERM]\n",
    "        self.hidden_states = list(range(len(y_unique))) # from state name to state index in hidden_idx2state\n",
    "        self.h_dim = len(number of hidden states)\n",
    "        \n",
    "        x_unique = []\n",
    "        for observed_list in x:\n",
    "            for observed_state in observed_list:\n",
    "                if observed_state not in x_unique:\n",
    "                    x_unique.append(observed_state)\n",
    "        x_unique.append(REST)\n",
    "        self.observed_idx2state = x_unique # lisf of unique observed states in train sequence + [REST]\n",
    "        self.observed_states = list(range(len(x_unique))) # from state name to state index in observed_idx2state\n",
    "        self.o_dim = len(observed_states)\n",
    "        \n",
    "        #######################       \n",
    "        \n",
    "        \n",
    "        #######################\n",
    "        # estimate emission matrix\n",
    "        # YOUR CODE HERE\n",
    "        self.B = sparse.csr_matrix((h_dim, o_dim)) #sparse csr matrix of shape (h_dim, o_dim)\n",
    "        #######################\n",
    "        \n",
    "        self.B_rowsum = np.ravel(self.B.sum(axis=1))\n",
    "        \n",
    "        ########################\n",
    "        # transition matrix\n",
    "        # YOUR CODE HERE\n",
    "        self.A = sparse.csr_matrix((h_dim **2, h_dim)) #dense matrix of shape (h_dim **2, h_dim)\n",
    "        # remember about padding for sequence of hidden states, eg {a, b} -> {START, START, a, b, TERM}\n",
    "        ########################\n",
    "        \n",
    "        self.A_rowsum = np.ravel(self.A.sum(axis=1))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tr_prob(self, i, j):\n",
    "        \"\"\"\n",
    "        A_ij = q(j | i) = q(j| u, v) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        A_ij = (count(u,v,i)+1)/(count(u,v)+V)\n",
    "        result = # smoothed probability\n",
    "        ########################\n",
    "        return result\n",
    "    \n",
    "    def em_prob(self, i, j):\n",
    "        \"\"\"\n",
    "        B_jk = e(x_k| j) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        # result = smoothed probability\n",
    "        ########################\n",
    "        return result\n",
    "    \n",
    "         \n",
    "    def o_state(self, x):\n",
    "        \"\"\"\n",
    "        return index of obseved state\n",
    "        \"\"\"\n",
    "        return self.observed_states.get(x, self.observed_states[self.REST])\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the most probable sequence of hidden states for every sequence of observed states\n",
    "        X - list of lists\n",
    "        \"\"\"\n",
    "        y_pred = [self._viterbi(seq) for seq in tqdm(X)]\n",
    "        return y_pred \n",
    "            \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        X - list of observables\n",
    "        product of probabilities usually is not numerically stable\n",
    "        remember, that log(ab) = log(a) + log(b) and argmax[log(f(x))] = argmax[f(x)]\n",
    "        \n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # pi[t, u, v] - max probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        pi = np.zeros((T + 1, self.h_dim, self.h_dim))\n",
    "        # backpointers, bp[t, u, v] = argmax probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        ###################\n",
    "        # fill tables pi and bp\n",
    "        # pi[t, u, v] = max_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # YOUR CODE HERE \n",
    "#         for k in range(1, T + 1):\n",
    "#             xk = self.o_state(X[k-1])\n",
    "            \n",
    "#             for v in range(self.h_dim):\n",
    "#                 log_b_smoothed = \n",
    "#                 for u in range(self.h_dim): \n",
    "#                     r = np.zeros(self.h_dim)\n",
    "#                     for w in range(self.h_dim):\n",
    "#                         log_a_smoothed = \n",
    "#                         r[w] = \n",
    "#                     bp[k, u, v] = np.argmax(r)\n",
    "#                     pi[k, u, v] = np.max(r)\n",
    "        ###################\n",
    "    \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # YOUR CODE HERE\n",
    "        # u, v = \n",
    "        ###################\n",
    "\n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        # h_states = \n",
    "            \n",
    "        ###################        \n",
    "            \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problem 1. Part of speech tagging\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3010]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):       \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hh = HMM().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problem 1.2 Vectorized viterbi\n",
    "\n",
    "class HmmVectorized(HMM):\n",
    "    \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        Vectorized version of Viterbi. Let's speed up!\n",
    "        X - list of observables\n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # One may notice, at every step t we only need pi[t-1, u, v] = pi_prev[u,v] to compute pi[t, u, v] = pi_curr[u,v]\n",
    "        pi_prev = np.zeros((self.h_dim, self.h_dim))\n",
    "        \n",
    "        # backpointers\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        a_rowsum = self.A_rowsum.reshape(self.h_dim, self.h_dim)\n",
    "        \n",
    "        ###################\n",
    "        # fill pi and bp\n",
    "        # pi_curr[u, v] = max_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # don't use tr_prob() and em_prob(), apply laplace smoothing directly here\n",
    "        # YOUR CODE HERE\n",
    "#         for k in range(1, T + 1):            \n",
    "#             xk = self.o_state(X[k-1])\n",
    "#             pi_curr = np.zeros_like(pi_prev)\n",
    "            \n",
    "#             for v in range(self.h_dim):\n",
    "#                 log_b_smoothed = \n",
    "#                 a = self.A[:, v].reshape(self.h_dim, self.h_dim)\n",
    "#                 log_a_smoothed = \n",
    "#                 r =  \n",
    "#                 bp[k, :, v] = np.argmax(r, axis=1)\n",
    "#                 pi_curr[:, v] = np.max(r, axis=1)\n",
    "                    \n",
    "#             pi_prev = pi_curr\n",
    "        ###################\n",
    "    \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # express r(u,v) as matrix additions\n",
    "        # YOUR CODE HERE\n",
    "        # u, v = \n",
    "        ###################\n",
    "        \n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        # h_states = \n",
    "            \n",
    "        ###################\n",
    "        \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3300]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hh = HmmVectorized().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Problem 2. Spelling correction\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
